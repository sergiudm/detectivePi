{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Thread-Everything\uff1aAn easy-to-use interface to run threads from different machines","text":""},{"location":"#introduction","title":"Introduction","text":"<p>Thread-Everything is a powerful and user-friendly Python framework that simplifies multi-threaded communication and control across different devices. It supports Windows and Linux, works seamlessly on x86 and ARM architectures, and enables you to effortlessly deploy and coordinate tasks across multiple machines.</p> <p>Thread-Everything empowers you to:</p> <ul> <li> <p>Easily distribute your functionalities to separate devices for enhanced performance and flexibility.</p> </li> <li> <p>Effortlessly orchestrate multi-device communication using a unified API.</p> </li> <li> <p>Develop custom applications via an intuitive plugin system, tailoring Thread-Everything to your specific needs.</p> </li> </ul> <p>Imagine these possibilities:</p> <ul> <li> <p>Controlling a remote robot army with a single Windows client.</p> </li> <li> <p>Creating immersive online action games based on real-time gesture recognition.</p> </li> <li> <p>Building a smart KTV system with gesture-controlled song selection and dynamic lighting.</p> </li> <li> <p>Developing a universal GPIO scheduler for simplified hardware control - perfect for streamlining university lab assignments.</p> </li> </ul>"},{"location":"#architecture","title":"Architecture","text":"<p><pre><code>graph TD\n    subgraph \"Resource Manager\"\n        C[config.json]\n        C--&gt;P[Assets Loader]\n    end\n\n    subgraph \"Core Components\"\n        B(Plugin Manager) -- loads--&gt; C\n        B --&gt; D[Runner Engine]\n        D --&gt; E[State Machine]\n        D --&gt; N[Vision Engine]\n        D --&gt; F[Music Engine]\n    end\n\n    subgraph \"Plugins (modules)\"\n        F --&gt; G[Music Player]\n        D --&gt; J[Other User Defined Plugins] \n        N --&gt; H[Body Feature Extractor]\n        N --&gt; O[Gesture detector]\n        E --&gt; I[GPIO Controller]\n    end\n\n    subgraph \"Communication Module\"\n      D --&gt; K[Socket Module]\n      D --&gt; L[Mailbot]\n      K &lt;--&gt; M[Other Machines]\n    end\n\n\n\n    style B fill:#336,stroke:#ccc,stroke-width:2px\n    style D fill:#363,stroke:#ccc,stroke-width:2px\n    style G fill:#663,stroke:#ccc,stroke-width:2px\n    style H fill:#663,stroke:#ccc,stroke-width:2px\n    style I fill:#663,stroke:#ccc,stroke-width:2px\n    style J fill:#663,stroke:#ccc,stroke-width:2px\n    style O fill:#663,stroke:#ccc,stroke-width:2px\n    style K fill:#336,stroke:#ccc,stroke-width:2px\n    style L fill:#336,stroke:#ccc,stroke-width:2px</code></pre> Thread-Everything's core is a robust plugin scheduler that loads and manages the execution of individual plugins. Each plugin is a self-contained Python module designed for a specific task, such as:</p> <ul> <li> <p>GPIO control</p> </li> <li> <p>Facial recognition</p> </li> <li> <p>Music playback</p> </li> </ul> <p>...and much more!</p> <p>The plugin scheduler is highly configurable through a unified config.json file. To streamline plugin development, we've provided powerful core components, including:</p> <ul> <li> <p>Vision Engine: Simplifies computer vision tasks.</p> </li> <li> <p>Music Engine: Facilitates audio management and playback.</p> </li> <li> <p>State Machine: Enables complex state-based logic.</p> </li> </ul> <p>Built upon this framework are several pre-built plugins like:</p> <ul> <li> <p>Gesture Detection:</p> </li> <li> <p>Uses your computer's camera to detect hand gestures (e.g., \"OK,\" \"Thumbs Up\").</p> </li> <li> <p>Sends recognized gestures to other devices via the communication module.</p> </li> <li> <p>Posture Detection:</p> <ul> <li>Analyzes your posture using the camera and provides feedback on whether you're sitting upright or slouching.</li> </ul> </li> <li> <p>Music Control:</p> </li> <li> <p>Controls music playback on your device (play/pause, volume, etc.).</p> </li> <li> <p>Can be controlled via command line input or integrated with other plugins like gesture detection.</p> </li> <li> <p>Simply place music files in the designated directory for automatic playback.</p> </li> <li> <p>Universal GPIO Controller (Raspberry Pi Only):</p> </li> <li> <p>Provides control over GPIO pins on a Raspberry Pi.</p> </li> <li> <p>Can be integrated with other plugins for advanced automation.</p> </li> <li> <p>Personalized Mailbot:</p> </li> <li> <p>Sends customized emails based on events triggered by other plugins.</p> </li> <li> <p>Can include images captured by the camera or other relevant data.</p> </li> </ul> <p>Furthermore, the communication module enables seamless peer-to-peer (P2P) communication between devices.</p>"},{"location":"#contributing","title":"Contributing","text":"<p>This project is open to contributions. You can contribute in the following ways:</p> <ul> <li>Add more plugins</li> <li>Improve the existing code</li> </ul>"},{"location":"#future-work","title":"Future Work","text":"<ul> <li> <p>Enhanced Vision Engine:</p> </li> <li> <p>Move beyond the current reliance on MediaPipe to create a more generic vision processing module.</p> </li> <li> <p>Support for different vision libraries and custom algorithms.</p> </li> <li> <p>Integrated Voice Processing Module:</p> </li> <li> <p>Add basic voice processing capabilities for remote calling, voice input, and other plugin enhancements.</p> </li> <li> <p>Improved GPIO Controller:</p> </li> <li> <p>Expand the GPIO controller to support advanced features like PWM and I2C.</p> </li> </ul>"},{"location":"#acknowledgement","title":"Acknowledgement","text":"<p>This project is built on the following libraries:</p> <ul> <li> <p>mediapipe</p> </li> <li> <p>opencv</p> </li> <li> <p>pygame</p> </li> <li> <p>RPi.GPIO</p> </li> </ul> <p>Thanks for their great work!</p>"},{"location":"about/","title":"About Thread-Everything","text":"<p>Thread-Everything is a powerful and user-friendly cross-platform framework designed to simplify the development of applications that require multi-device communication and control. It empowers developers to effortlessly distribute tasks across multiple machines, enabling the creation of innovative and interconnected systems.</p>"},{"location":"about/#our-mission","title":"Our Mission","text":"<p>Our mission is to provide a flexible and intuitive tool that breaks down the barriers of inter-device communication. We believe that connecting different devices should be seamless and accessible to everyone, regardless of their technical expertise. Thread-Everything aims to democratize the development of distributed applications, fostering creativity and enabling the realization of complex, multi-device projects with ease.</p>"},{"location":"about/#what-makes-thread-everything-special","title":"What Makes Thread-Everything Special?","text":"<ul> <li>Cross-Platform Compatibility: Works seamlessly on Windows, Linux, x86, and ARM architectures.</li> <li>Easy-to-Use Python API: Simplifies multi-threaded programming and inter-process communication.</li> <li>Plugin Architecture: Extend the framework's functionality with custom Python modules tailored to your specific needs.</li> <li>Powerful Core Components: Leverage built-in engines for computer vision, music processing, and state management.</li> <li>Versatile Communication Module: Facilitates peer-to-peer communication between devices.</li> <li>Active Development and Community: We are continuously improving Thread-Everything and welcome contributions from the community.</li> </ul>"},{"location":"about/#example-applications","title":"Example Applications","text":"<p>Thread-Everything is a versatile tool that can be used in various domains. Here are some of the real-world application examples developed using our framework:</p> <ul> <li>Smart KTV: Develop a smart KTV system that controls song selection and adjusts room atmosphere through hand gestures.</li> <li>Remote Robot Control: Utilize a simple Windows client to control remote robots.</li> <li>Meditation Assistant: Create a visual meditation aid that provides posture feedback and tracks meditation time using non-contact methods.</li> <li>Smart Gym: Enhance your workout experience with gesture-controlled music and real-time pace analysis.</li> <li>Anti-Distraction App: Stay focused by detecting and receiving alerts for unwanted distractions.</li> </ul>"},{"location":"about/#get-involved","title":"Get Involved","text":"<p>We encourage you to explore Thread-Everything, experiment with its capabilities, and contribute to its growth. Visit our GitHub repository to access the code, documentation, and contribution guidelines.</p> <p>Join us in shaping the future of multi-device applications!</p>"},{"location":"applications/","title":"Example Applications","text":"<p>Thread-Everything's versatility allows it to be used in a wide range of applications. Here are a few examples built using the existing plugins:</p>"},{"location":"applications/#visual-meditation-assistant","title":"Visual Meditation Assistant:","text":""},{"location":"applications/#problem-meditators-want-a-distraction-free-environment-and-a-way-to-track-their-posture-without-using-their-phones-or-alarms","title":"Problem: Meditators want a distraction-free environment and a way to track their posture without using their phones or alarms.","text":""},{"location":"applications/#solution-thread-everythings-vision-engine-powers-a-contactless-meditation-timer-with-posture-correction","title":"Solution: Thread-Everything's vision engine powers a contactless meditation timer with posture correction.","text":""},{"location":"applications/#how-it-works","title":"How it works:","text":"<p>Users set the meditation duration using hand gestures.</p> <p>During meditation, a Raspberry Pi or Windows machine monitors posture via the camera.</p> <p>Configurable alerts (e.g., lights) signal poor posture.</p> <p>A summary email with posture snapshots is sent upon completion.</p>"},{"location":"applications/#smart-gym-pace-detection-and-bgm-control","title":"Smart Gym - Pace Detection and BGM Control:","text":""},{"location":"applications/#features","title":"Features:","text":"<ul> <li> <p>Control gym lighting and music using pull-up movements.</p> </li> <li> <p>Accurately measure running or elliptical pace using computer vision (more precise than wearables).</p> </li> <li> <p>Receive detailed workout reports via email, including snapshots and peak pace.</p> </li> <li> <p>Control music playback (next song, play/pause) using hand gestures.</p> </li> </ul>"},{"location":"applications/#anti-distraction-app","title":"Anti-Distraction App:","text":"<p>Detects late-night studying (or other distractions) and sends a reminder email.</p>"},{"location":"getting-started/","title":"Getting Started","text":""},{"location":"getting-started/#environment-requirements","title":"Environment Requirements","text":"Environment Version OS Ubuntu22.04, Raspberry Pi OS, Window11 Python &gt;=3.8"},{"location":"getting-started/#installation","title":"Installation","text":""},{"location":"getting-started/#pip-install","title":"pip install","text":"Bash<pre><code>pip install Thread-Everything\n</code></pre>"},{"location":"getting-started/#source-code-installation","title":"Source code installation","text":"Bash<pre><code>git clone https://github.com/sergiudm/Thread-Everything.git\ncd detective\nconda create -n detective python=3.10 -y\necho \"conda environment created\"\nconda activate detective\npip install -r requirements.txt\n</code></pre>"},{"location":"getting-started/#usage","title":"Usage","text":"<p>Before you start, you need to create a <code>config.json</code> file in the root directory of the project, Here is an example(you can find it in the <code>config_template.json</code>):</p> JSON<pre><code>{\n    \"use_pi\": false,\n    \"plugin_list\": [ # Note: plugins related to GPIO need to enable `use_pi`, if you don't use GPIO-related libraries, turn it off\n        \"information_server\",\n        \"GPIO_controller\",\n        \"music_server\",\n        \"gpio_controller\",\n    ],\n    \"default_detect_mode\": \"others\",\n    \"use_camera\": true,\n    \"use_visualization\": false, # if you want to see the detection result, set it to true\n    \"server_email\": \"youremail@example.com\",\n    \"server_email_password\": \"your email password\",# Note: if you use QQ email, you need to set an app password\n    \"target_email\": [\n        \"email1\",\n        \"email2\"\n    ],\n    \"smtp_server\":\"your smtp server\",\n    \"smtp_port\": 587,\n    \"video_path\": \"assets/videos/sit.mp4\", # if you want to use a video file for detection, set it here\n    \"image_path\": \"resources\", # if you want to use an image file for detection, set it here\n    \"send_delay\": 13, # the interval between sending emails\n    \"effective_detection_duration\": 2,\n    \"max_num_hands\": 2,\n    \"min_detection_confidence\": 0.65,\n    \"min_tracking_confidence\": 0.65,\n    \"pin_data\": {\n        \"pin_list\": [ # if you use GPIO, you need to set the pin list\n            17,\n            23,\n            24,\n            25,\n            27\n        ],\n        \"pin_map\": { # mapping the gesture to the pin\n            \"Right\": [\n                17,\n                23,\n                24\n            ],\n            \"Return\": [\n                23,\n                24\n            ],\n            \"Left\": [\n                17,\n                24\n            ],\n            \"Pause\": [],\n            \"Like\": [\n                25\n            ],\n            \"OK\": [\n                27\n            ]\n        }\n    }\n}\n</code></pre> <p>Warning</p> <p>In the <code>config.json</code> file, you need to remove all the comments before running the program.     </p>"},{"location":"getting-started/#run-the-program","title":"Run the program","text":"<p>Linux: Bash<pre><code>sudo chmod +x run.sh\n./run.sh\n</code></pre> Windows: Bash<pre><code>./win_run.bat\n</code></pre></p>"},{"location":"plugins-tutorial/","title":"How to write your own plugins","text":"<p>Thread-Everything is a highly extensible project that allows you to define your own plugins in the <code>modules</code> directory. We have implemented some plugins, they lie in:</p> <p>Text Only<pre><code>.\n\u251c\u2500\u2500 common.py\n\u251c\u2500\u2500 detect_others.py\n\u251c\u2500\u2500 gesture.py\n\u251c\u2500\u2500 gpio_controller.py\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 meditation_assistant.py\n\u251c\u2500\u2500 music_player.py\n\u2514\u2500\u2500 utils.py\n</code></pre> To integrate your own function, you should: 1. Implement all your features in a Python module. 2. Encaplulate all your functions to a single function. 3. Create a new thread instance in `detective.runner.runner_engine, together with your arguments.</p> <p>Here is a step-by-step demontration:</p>"},{"location":"plugins-tutorial/#create-a-new-python-module","title":"Create a new Python module","text":"<p>In this example, we implement a music player feature in <code>music_player.py</code> which lies in <code>detective/runner</code>, and the class is defined as: Python<pre><code>class MusicPlayer:\n    def __init__(\n        self, music_dir, volume_step=5, volume_update_interval=0.5\n    ):\n        pygame.init()\n        pygame.mixer.init()\n\n        self.music_dir = music_dir\n        self.playlist = self.load_playlist()\n        self.current_track_index = 0\n        self.ch_mode = \"sequence\"  # \"sequence\", \"shuffle\", \"single\"\n        self.volume = 50  # Initial volume\n        pygame.mixer.music.set_volume(self.volume / 100.0)\n        self.is_playing = False\n        self.last_gesture = None\n        self.volume_timer = 0\n        self.volume_step = volume_step\n        self.volume_update_interval = volume_update_interval\n        self.load_current_track()\n\n    def load_playlist(self):\n        \"\"\"Loads all .mp3 and .wav files from the music directory into a playlist.\"\"\"\n        playlist = []\n        for filename in os.listdir(self.music_dir):\n            if filename.endswith((\".mp3\", \".wav\")):  # Add other audio formats if needed\n                playlist.append(os.path.join(self.music_dir, filename))\n        if not playlist:\n            print(\n                \"Warning: no music file detected, please check ./assets/music directory\"\n            )\n        return playlist\n\n    def load_current_track(self):\n        \"\"\"Loads the current track from the playlist.\"\"\"\n        if 0 &lt;= self.current_track_index &lt; len(self.playlist):\n            try:\n                pygame.mixer.music.load(self.playlist[self.current_track_index])\n                print(f\"Loaded track: {self.playlist[self.current_track_index]}\")\n            except pygame.error as e:\n                print(f\"Error loading track: {self.playlist[self.current_track_index]}\")\n                print(e)\n                # Handle the error (e.g., remove the track from the playlist, skip to the next)\n                self.playlist.pop(self.current_track_index)\n                self.current_track_index = max(\n                    0, self.current_track_index - 1\n                )  # prevent index out of range\n                self.load_current_track()  # recursively load next track\n\n    def play_music(self):\n        \"\"\"Plays the current track.\"\"\"\n        if self.playlist:\n            pygame.mixer.music.play()\n            self.is_playing = True\n\n    def gesture_decode(self, gesture):\n        current_time = time.time()\n\n        # Edge detection for ch_mode, play_next, pause, resume\n        if gesture != self.last_gesture:\n            if gesture == \"OK\":\n                self.toggle_ch_mode()\n                print(f\"Change mode toggled to: {self.ch_mode}\")\n            elif gesture == \"Like\":\n                self.play_next()\n                print(\"Play next\")\n            elif gesture == \"Return\":\n                if not self.is_playing:\n                    self.resume()\n                    print(\"Resume\")\n            elif gesture == \"Pause\":\n                if self.is_playing:\n                    self.pause()\n                    print(\"Pause\")\n\n        # Volume control with timer\n        if gesture == \"Right\":\n            if current_time - self.volume_timer &gt; self.volume_update_interval:\n                self.volume_down()\n                self.volume_timer = current_time\n        elif gesture == \"Left\":\n            if current_time - self.volume_timer &gt; self.volume_update_interval:\n                self.volume_up()\n                self.volume_timer = current_time\n\n        self.last_gesture = gesture\n\n        # Check if the current song has ended\n        if self.is_playing and not pygame.mixer.music.get_busy():\n            self.handle_song_end()\n\n    def toggle_ch_mode(self):\n        if self.ch_mode == \"sequence\":\n            self.ch_mode = \"shuffle\"\n        elif self.ch_mode == \"shuffle\":\n            self.ch_mode = \"single\"\n        else:\n            self.ch_mode = \"sequence\"\n\n    def volume_up(self):\n        self.volume = min(100, self.volume + self.volume_step)\n        pygame.mixer.music.set_volume(self.volume / 100.0)\n        print(f\"Volume up: {self.volume}\")\n\n    def volume_down(self):\n        self.volume = max(0, self.volume - self.volume_step)\n        pygame.mixer.music.set_volume(self.volume / 100.0)\n        print(f\"Volume down: {self.volume}\")\n\n    def pause(self):\n        pygame.mixer.music.pause()\n        self.is_playing = False\n\n    def resume(self):\n        pygame.mixer.music.unpause()\n        self.is_playing = True\n\n    def play_next(self):\n        if self.ch_mode == \"sequence\":\n            self.current_track_index = (self.current_track_index + 1) % len(\n                self.playlist\n            )\n        elif self.ch_mode == \"shuffle\":\n            self.current_track_index = random.randint(0, len(self.playlist) - 1)\n        # \"single\" mode doesn't change the track\n        self.load_current_track()\n        self.play_music()\n\n    def handle_song_end(self):\n        if self.ch_mode == \"sequence\":\n            self.current_track_index = (self.current_track_index + 1) % len(\n                self.playlist\n            )\n        elif self.ch_mode == \"shuffle\":\n            self.current_track_index = random.randint(0, len(self.playlist) - 1)\n        # In \"single\" mode, we just stop\n        if self.ch_mode != \"single\":\n            self.load_current_track()\n            self.play_music()\n\n    def stop(self):\n        pygame.mixer.music.stop()\n        self.is_playing = False\n</code></pre></p>"},{"location":"plugins-tutorial/#create-the-function","title":"Create the function","text":"<p>Then create a single function: Python<pre><code>def music_play(music_player, resent_gesture_queue, initial_volume=50):\n    try:\n        music_player.volume = initial_volume\n        pygame.mixer.music.set_volume(music_player.volume / 100.0)\n        music_player.play_music()\n\n        while True:\n            if not resent_gesture_queue.empty():\n                gesture = resent_gesture_queue.get()\n                music_player.gesture_decode(gesture)\n            time.sleep(0.1)\n    except Exception as e:\n        print(f\"Error: {e}\")\n    finally:\n        pygame.quit()\n</code></pre> You may need to import external packages.</p>"},{"location":"plugins-tutorial/#create-a-thread-instance","title":"Create a thread instance","text":"<p>In <code>detective/runner/runner_engine</code>, create a <code>music_thread</code> instance. Python<pre><code>music_thread = threading.Thread(\n        target=music_play,\n        args=(\n            music_player,\n            resent_gesture_queue,\n        ),\n    )\n</code></pre> You also need to assign a name so that the config parser can load the plugin. Python<pre><code>def name2thread(name):\n            return {\n                \"information_server\": server_thread,\n                \"working_detect\": working_detect_thread,\n                \"music_server\": music_thread, # this is the new plugin\n                \"gpio_controller\": gpio_controller_thread,\n                \"gesture_detection\": gesture_detection_thread,\n                \"meditation_helper\": meditation_helper_thread,\n            }[name]\n</code></pre></p>"},{"location":"plugins-tutorial/#load-your-plugin-in-the-configjson-file","title":"Load your plugin in the <code>config.json</code> file","text":"<p>Finally, configure your plugin in the <code>config.json</code>,  JSON<pre><code>{\n    // ...\n    \"plugin_list\": [\n        // other plugins\n        \"music_server\"\n    ]\n    // ...\n}\n</code></pre> and then you can launch your plugin!</p>"},{"location":"user-guide/","title":"User Guide","text":"<p>TBD</p>"}]}